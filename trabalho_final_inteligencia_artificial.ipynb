{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zcmFrwX1fpR",
    "outputId": "0948382c-0e4d-41c0-9c66-f42a3bf31cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configurando ambiente Google Colab com GitHub ---\n",
      "Clonando repositÃ³rio: https://github.com/kralluz/trabalho_inteligencia_artificial.git...\n",
      "Cloning into 'trabalho_inteligencia_artificial'...\n",
      "remote: Enumerating objects: 771, done.\u001b[K\n",
      "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
      "remote: Total 771 (delta 4), reused 8 (delta 3), pack-reused 759 (from 2)\u001b[K\n",
      "Receiving objects: 100% (771/771), 324.00 MiB | 13.11 MiB/s, done.\n",
      "Resolving deltas: 100% (29/29), done.\n",
      "Updating files: 100% (212/212), done.\n",
      "DiretÃ³rio de trabalho atual: /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial\n",
      "\n",
      "Verificando conteÃºdo do diretÃ³rio do projeto (primeiros 5 itens):\n",
      "- .git\n",
      "- .gitignore\n",
      "- README.md\n",
      "- converter_dataset_novo.py\n",
      "- dataset_novo\n",
      "... e mais 7 itens.\n",
      "\n",
      "--- ConfiguraÃ§Ã£o inicial e clone do GitHub concluÃ­dos ---\n"
     ]
    }
   ],
   "source": [
    "# CÃ©lula 1: Clonar o RepositÃ³rio GitHub e Mudar para o DiretÃ³rio do Projeto\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "print(\"--- Configurando ambiente Google Colab com GitHub ---\")\n",
    "\n",
    "# --- PARÃ‚METROS DO SEU REPOSITÃ“RIO ---\n",
    "# URL do seu repositÃ³rio GitHub\n",
    "GIT_REPO_URL = 'https://github.com/kralluz/trabalho_inteligencia_artificial.git'\n",
    "\n",
    "# Nome da pasta do repositÃ³rio apÃ³s o clone (geralmente o nome do repositÃ³rio)\n",
    "REPO_NAME = 'trabalho_inteligencia_artificial'\n",
    "# -----------------------------------\n",
    "\n",
    "# Clonar o repositÃ³rio\n",
    "print(f\"Clonando repositÃ³rio: {GIT_REPO_URL}...\")\n",
    "if os.path.exists(REPO_NAME):\n",
    "    print(f\"DiretÃ³rio '{REPO_NAME}' jÃ¡ existe. Removendo para clonar novamente...\")\n",
    "    !rm -rf {REPO_NAME}\n",
    "!git clone {GIT_REPO_URL}\n",
    "\n",
    "# Mudar o diretÃ³rio de trabalho para a raiz do repositÃ³rio clonado\n",
    "# Isso Ã© crucial para que os caminhos relativos no seu script funcionem\n",
    "os.chdir(REPO_NAME)\n",
    "print(f\"DiretÃ³rio de trabalho atual: {os.getcwd()}\")\n",
    "\n",
    "print(\"\\nVerificando conteÃºdo do diretÃ³rio do projeto (primeiros 5 itens):\")\n",
    "try:\n",
    "    listed_items = os.listdir('.')\n",
    "    for i, item in enumerate(listed_items[:5]):\n",
    "        print(f\"- {item}\")\n",
    "    if len(listed_items) > 5:\n",
    "        print(f\"... e mais {len(listed_items) - 5} itens.\")\n",
    "    elif not listed_items:\n",
    "        print(\"O diretÃ³rio do projeto parece estar vazio apÃ³s o clone.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao listar o diretÃ³rio: {e}\")\n",
    "\n",
    "print(\"\\n--- ConfiguraÃ§Ã£o inicial e clone do GitHub concluÃ­dos ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pLEHpFBE13Y6",
    "outputId": "6aef683c-cded-4a42-e3c2-9ba9024ab3b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [1/6] Instalando dependÃªncias... ---\n",
      "Executando: pip install ultralytics==8.3.153 --quiet\n",
      "âœ“ ultralytics==8.3.153 instalado/verificado.\n",
      "Executando: pip install Pillow numpy matplotlib --quiet\n",
      "âœ“ Pillow instalado/verificado.\n",
      "\n",
      "--- InstalaÃ§Ã£o de dependÃªncias concluÃ­da ---\n"
     ]
    }
   ],
   "source": [
    "# CÃ©lula 2: InstalaÃ§Ã£o de DependÃªncias\n",
    "print(\"--- [1/6] Instalando dependÃªncias... ---\")\n",
    "\n",
    "deps = [\n",
    "    \"pip install ultralytics==8.3.153 --quiet\",\n",
    "    \"pip install Pillow numpy matplotlib --quiet\"\n",
    "]\n",
    "\n",
    "for dep in deps:\n",
    "    try:\n",
    "        print(f\"Executando: {dep}\")\n",
    "        # Usamos '!' para executar comandos de shell diretamente no Colab\n",
    "        !{dep}\n",
    "        print(f\"âœ“ {dep.split()[2]} instalado/verificado.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Erro ao instalar {dep.split()[2]}: {e}\")\n",
    "        print(f\"~ {dep.split()[2]} (pode jÃ¡ estar instalado ou houve outro problema).\")\n",
    "\n",
    "print(\"\\n--- InstalaÃ§Ã£o de dependÃªncias concluÃ­da ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NhQujC-i16h7",
    "outputId": "1b0b3c2b-e1d2-4826-cc24-61746f485d5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Definindo funÃ§Ãµes do projeto ---\n",
      "\n",
      "--- FunÃ§Ãµes definidas ---\n"
     ]
    }
   ],
   "source": [
    "# CÃ©lula 3: DefiniÃ§Ã£o das FunÃ§Ãµes do Script\n",
    "print(\"--- Definindo funÃ§Ãµes do projeto ---\")\n",
    "\n",
    "def configurar_dataset_novo():\n",
    "    \"\"\"Configura o dataset YOLO novo (convertido com alta qualidade)\"\"\"\n",
    "    print(\"ğŸš— Configurando dataset YOLO novo (alta qualidade)...\")\n",
    "\n",
    "    base_path = os.getcwd()\n",
    "    dataset_path = os.path.join(base_path, \"dataset_yolo_novo\")\n",
    "    yaml_path = os.path.join(dataset_path, \"data.yaml\")\n",
    "\n",
    "    # Verificar se o dataset existe\n",
    "    if not os.path.exists(dataset_path):\n",
    "        print(\"âŒ Dataset YOLO novo nÃ£o encontrado!\")\n",
    "        print(\"ğŸ’¡ Certifique-se de que 'dataset_yolo_novo' estÃ¡ na raiz do seu repositÃ³rio GitHub.\")\n",
    "        return None\n",
    "\n",
    "    if not os.path.exists(yaml_path):\n",
    "        print(\"âŒ Arquivo data.yaml nÃ£o encontrado!\")\n",
    "        print(f\"ğŸ’¡ Certifique-se de que '{yaml_path}' existe no seu repositÃ³rio GitHub.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"âœ… Dataset YOLO novo configurado: {dataset_path}\")\n",
    "    print(f\"ğŸ“„ Usando configuraÃ§Ã£o: {yaml_path}\")\n",
    "\n",
    "    # Verificar estrutura do dataset\n",
    "    total_annotations = 0\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        img_dir = os.path.join(dataset_path, split, 'images')\n",
    "        lbl_dir = os.path.join(dataset_path, split, 'labels')\n",
    "\n",
    "        if os.path.exists(img_dir) and os.path.exists(lbl_dir):\n",
    "            img_count = len([f for f in os.listdir(img_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            lbl_count = len([f for f in os.listdir(lbl_dir) if f.lower().endswith('.txt')])\n",
    "\n",
    "            # Contar anotaÃ§Ãµes\n",
    "            for lbl_file in os.listdir(lbl_dir):\n",
    "                if lbl_file.lower().endswith('.txt'):\n",
    "                    lbl_path = os.path.join(lbl_dir, lbl_file)\n",
    "                    with open(lbl_path, 'r') as f:\n",
    "                        total_annotations += len(f.readlines())\n",
    "\n",
    "            print(f\"  ğŸ“‚ {split}: {img_count} imagens, {lbl_count} labels\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ {split}: diretÃ³rio '{split}' nÃ£o encontrado ou incompleto em {dataset_path}\")\n",
    "\n",
    "    print(f\"ğŸ“Š Total de anotaÃ§Ãµes: {total_annotations}\")\n",
    "    return yaml_path\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"TRABALHO FINAL - INTELIGENCIA ARTIFICIAL\")\n",
    "    print(\"DetecÃ§Ã£o de Vagas de Estacionamento com YOLO\")\n",
    "    print(\"VERSÃƒO FINAL - DATASET NOVO DE ALTA QUALIDADE\")\n",
    "    print(\"903 anotaÃ§Ãµes precisas em 30 imagens\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    print(\"\\n[1/6] Instalando dependÃªncias...\") # Esta etapa Ã© para referÃªncia, jÃ¡ que a CÃ©lula 2 a executa\n",
    "    deps = [\n",
    "        \"pip install ultralytics==8.3.153 --quiet\",\n",
    "        \"pip install Pillow numpy matplotlib --quiet\"\n",
    "    ]\n",
    "\n",
    "    for dep in deps:\n",
    "        try:\n",
    "            # NÃ£o Ã© necessÃ¡rio usar subprocess.run aqui, jÃ¡ que o '!pip' funciona no Colab\n",
    "            # Mas mantemos para compatibilidade com o script original se for executado localmente\n",
    "            subprocess.run(dep, shell=True, check=True, capture_output=True)\n",
    "            print(f\"âœ“ {dep.split()[2]}\")\n",
    "        except:\n",
    "            print(f\"~ {dep.split()[2]} (jÃ¡ instalado ou erro ao instalar)\")\n",
    "\n",
    "    print(\"\\n[2/6] Importando bibliotecas...\")\n",
    "    try:\n",
    "        import numpy as np\n",
    "        from PIL import Image\n",
    "        from ultralytics import YOLO\n",
    "        import torch\n",
    "        print(\"âœ“ Todas as bibliotecas importadas\")\n",
    "    except ImportError as e:\n",
    "        print(f\"âœ— Erro de importaÃ§Ã£o: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n[3/6] Configurando dataset YOLO novo (alta qualidade)...\")\n",
    "    try:\n",
    "        yaml_path = configurar_dataset_novo()\n",
    "        if yaml_path:\n",
    "            print(\"âœ… Dataset YOLO novo configurado com sucesso\")\n",
    "        else:\n",
    "            print(\"âŒ Erro ao configurar dataset YOLO novo\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Erro ao configurar dataset: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n[4/6] Carregando modelo YOLO...\")\n",
    "    try:\n",
    "        try:\n",
    "            model = YOLO('yolov8n.pt')\n",
    "            print(\"âœ“ Modelo prÃ©-treinado yolov8n.pt carregado\")\n",
    "        except Exception as e1:\n",
    "            print(f\"~ NÃ£o foi possÃ­vel carregar yolov8n.pt ({e1}), tentando yolov8n.yaml...\")\n",
    "            try:\n",
    "                model = YOLO('yolov8n.yaml')\n",
    "                print(\"âœ“ Modelo criado do zero a partir de yolov8n.yaml\")\n",
    "            except Exception as e2:\n",
    "                print(f\"âœ— Erro ao criar modelo com yolov8n.yaml: {e2}\")\n",
    "                return\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Erro fatal ao carregar/criar modelo: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n[5/6] Treinando modelo com dataset de alta qualidade...\")\n",
    "    try:\n",
    "        print(\"Iniciando treinamento (pode demorar alguns minutos)...\")\n",
    "        print(\"ğŸ“Š Dataset: 903 anotaÃ§Ãµes precisas de vagas!\")\n",
    "\n",
    "        import shutil\n",
    "        if os.path.exists('projeto_final_novo'):\n",
    "            print(\"Removendo treinamento anterior...\")\n",
    "            shutil.rmtree('projeto_final_novo')\n",
    "\n",
    "        # ConfiguraÃ§Ãµes de treinamento otimizadas para o novo dataset\n",
    "        results = model.train(\n",
    "            data=yaml_path,\n",
    "            epochs=150,           # Menos Ã©pocas pois o dataset Ã© de alta qualidade\n",
    "            batch=8,            # Batch maior pois temos menos imagens mas mais anotaÃ§Ãµes\n",
    "            imgsz=640,          # ResoluÃ§Ã£o maior para melhor precisÃ£o\n",
    "            device='cpu',       # Mantenha 'cpu' ou mude para '0'/'cuda' se for usar GPU\n",
    "            project='projeto_final_novo',\n",
    "            name='yolo_vagas_novo',\n",
    "            exist_ok=True,\n",
    "            pretrained=True,\n",
    "            optimizer='AdamW',  # Otimizador mais moderno\n",
    "            verbose=True,\n",
    "            seed=42,\n",
    "            deterministic=True,\n",
    "            patience=10,        # Early stopping mais agressivo\n",
    "            save_period=5,      # Salvar checkpoints a cada 5 Ã©pocas\n",
    "            val=True,\n",
    "            cache=False,\n",
    "            lr0=0.01,          # Learning rate inicial\n",
    "            warmup_epochs=3    # Warmup epochs\n",
    "        )\n",
    "        print(f\"âœ“ Treinamento concluÃ­do! Resultados salvos em: {results.save_dir}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Erro no treinamento: {e}\")\n",
    "        print(\"Detalhes do erro:\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"Continuando com validaÃ§Ã£o...\")\n",
    "\n",
    "    print(\"\\n[6/6] Testando modelo...\")\n",
    "    model_path_best = os.path.join('projeto_final_novo', 'yolo_vagas_novo', 'weights', 'best.pt')\n",
    "    model_path_last = os.path.join('projeto_final_novo', 'yolo_vagas_novo', 'weights', 'last.pt')\n",
    "\n",
    "    loaded_model = None\n",
    "    if os.path.exists(model_path_best):\n",
    "        try:\n",
    "            loaded_model = YOLO(model_path_best)\n",
    "            print(f\"âœ“ Modelo treinado carregado: {model_path_best}\")\n",
    "        except Exception as e_best:\n",
    "            print(f\"~ Problema ao carregar best.pt ({e_best}), tentando last.pt...\")\n",
    "            if os.path.exists(model_path_last):\n",
    "                try:\n",
    "                    loaded_model = YOLO(model_path_last)\n",
    "                    print(f\"âœ“ Modelo treinado carregado: {model_path_last}\")\n",
    "                except Exception as e_last:\n",
    "                    print(f\"~ Erro ao carregar last.pt ({e_last}). Teste abortado.\")\n",
    "    elif os.path.exists(model_path_last):\n",
    "        try:\n",
    "            loaded_model = YOLO(model_path_last)\n",
    "            print(f\"âœ“ Modelo treinado carregado: {model_path_last}\")\n",
    "        except Exception as e_last:\n",
    "            print(f\"~ Erro ao carregar last.pt ({e_last}). Teste abortado.\")\n",
    "    else:\n",
    "        print(\"~ Nenhum modelo treinado encontrado. Teste abortado.\")\n",
    "\n",
    "    if loaded_model:\n",
    "        try:\n",
    "            # DiretÃ³rio de teste\n",
    "            test_images_dir = os.path.join(os.path.dirname(yaml_path), 'test', 'images')\n",
    "\n",
    "            # Criar diretÃ³rio para resultados da inferÃªncia\n",
    "            results_dir = \"resultados_novo/predicoes_finais\"\n",
    "            os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "            print(f\"Realizando inferÃªncia nas imagens de teste em: {test_images_dir}\")\n",
    "            print(f\"Resultados serÃ£o salvos em: {results_dir}\")\n",
    "\n",
    "            # Realizar prediÃ§Ãµes com confianÃ§a mais baixa (0.1)\n",
    "            results_pred = loaded_model.predict(\n",
    "                source=test_images_dir,\n",
    "                save=True,\n",
    "                project=\"resultados_novo\",\n",
    "                name=\"predicoes_finais\",\n",
    "                exist_ok=True,\n",
    "                conf=0.1,   # ConfianÃ§a mais baixa para capturar mais detecÃ§Ãµes\n",
    "                iou=0.5,    # IoU para NMS\n",
    "                verbose=True\n",
    "            )\n",
    "\n",
    "            # Analisar resultados detalhadamente\n",
    "            total_detections = 0\n",
    "            for i, result in enumerate(results_pred):\n",
    "                if result.boxes is not None and len(result.boxes) > 0:\n",
    "                    detections = len(result.boxes)\n",
    "                    total_detections += detections\n",
    "                    print(f\"  ğŸ“¸ Imagem {i+1}: {detections} vagas detectadas\")\n",
    "\n",
    "                    # Mostrar detalhes das primeiras detecÃ§Ãµes\n",
    "                    if i < 3:  # Mostrar detalhes das 3 primeiras imagens\n",
    "                        for j, box in enumerate(result.boxes[:5]):  # Max 5 detecÃ§Ãµes por imagem\n",
    "                            cls = int(box.cls[0])\n",
    "                            conf = float(box.conf[0])\n",
    "                            class_name = loaded_model.names[cls]\n",
    "                            print(f\"    - Vaga {j+1}: {class_name} (confianÃ§a: {conf:.2f})\")\n",
    "                else:\n",
    "                    print(f\"  ğŸ“¸ Imagem {i+1}: 0 vagas detectadas\")\n",
    "\n",
    "            print(f\"âœ“ Teste concluÃ­do! {len(results_pred)} imagens processadas.\")\n",
    "            print(f\"ğŸ“Š Total de detecÃ§Ãµes: {total_detections}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"~ Erro no teste: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(\"~ Modelo nÃ£o carregado, pulando etapa de teste.\")\n",
    "\n",
    "    # Teste final com imagens para inferÃªncia\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸš— TESTE FINAL COM IMAGENS DE INFERÃŠNCIA\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # O caminho para as imagens de inferÃªncia estarÃ¡ dentro do repositÃ³rio clonado\n",
    "    inference_images_path = os.path.join(os.getcwd(), 'imagens_para_inferencia')\n",
    "\n",
    "    if loaded_model and os.path.exists(inference_images_path):\n",
    "        try:\n",
    "            print(f\"Realizando inferÃªncia final com dataset de alta qualidade em: {inference_images_path}\")\n",
    "\n",
    "            inference_results = loaded_model.predict(\n",
    "                source=inference_images_path,\n",
    "                save=True,\n",
    "                project='teste_final_novo',\n",
    "                name='inferencia_final',\n",
    "                exist_ok=True,\n",
    "                conf=0.1,   # ConfianÃ§a baixa para capturar mais detecÃ§Ãµes\n",
    "                iou=0.5,\n",
    "                verbose=True\n",
    "            )\n",
    "\n",
    "            # Analisar resultados da inferÃªncia final\n",
    "            total_detections = 0\n",
    "            for result in inference_results:\n",
    "                if result.boxes is not None:\n",
    "                    detections = len(result.boxes)\n",
    "                    total_detections += detections\n",
    "\n",
    "                    # Analisar por classe\n",
    "                    free_count = 0\n",
    "                    occupied_count = 0\n",
    "\n",
    "                    for box in result.boxes:\n",
    "                        cls = int(box.cls[0])\n",
    "                        conf = float(box.conf[0])\n",
    "\n",
    "                        if cls == 0:  # free_parking_space\n",
    "                            free_count += 1\n",
    "                        else:  # not_free_parking_space\n",
    "                            occupied_count += 1\n",
    "\n",
    "                    print(f\"  ğŸ“¸ {os.path.basename(result.path)}: {detections} vagas\")\n",
    "                    print(f\"    ğŸŸ¢ Livres: {free_count} | ğŸ”´ Ocupadas: {occupied_count}\")\n",
    "                else:\n",
    "                    print(f\"  ğŸ“¸ {os.path.basename(result.path)}: 0 vagas detectadas\")\n",
    "\n",
    "            print(f\"\\nâœ“ InferÃªncia final concluÃ­da! {len(inference_results)} imagens processadas.\")\n",
    "            print(f\"ğŸ“ Resultados salvos em: teste_final_novo/inferencia_final/\")\n",
    "            print(f\"ğŸ“Š Total de detecÃ§Ãµes: {total_detections}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Erro na inferÃªncia final: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(\"~ DiretÃ³rio 'imagens_para_inferencia' nÃ£o encontrado ou modelo nÃ£o carregado. Pulando inferÃªncia final.\")\n",
    "\n",
    "    # Resumo final\n",
    "    end_time = time.time()\n",
    "    duration = (end_time - start_time) / 60\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"PROJETO CONCLUÃDO COM DATASET DE ALTA QUALIDADE!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Tempo total: {duration:.1f} minutos\")\n",
    "\n",
    "    if os.path.exists('projeto_final_novo'):\n",
    "        print(\"\\nArquivos criados:\")\n",
    "        print(\"âœ“ dataset_yolo_novo/ - Dataset de alta qualidade (903 anotaÃ§Ãµes)\")\n",
    "        print(\"âœ“ projeto_final_novo/ - Modelo treinado\")\n",
    "        if os.path.exists('resultados_novo'):\n",
    "            print(\"âœ“ resultados_novo/ - PrediÃ§Ãµes do teste\")\n",
    "        if os.path.exists('teste_final_novo'):\n",
    "            print(\"âœ“ teste_final_novo/ - InferÃªncia final\")\n",
    "\n",
    "        print(\"\\nEste projeto demonstra:\")\n",
    "        print(\"â€¢ Uso de dataset de ALTA QUALIDADE com anotaÃ§Ãµes manuais precisas\")\n",
    "        print(\"â€¢ 903 anotaÃ§Ãµes de vagas em 30 imagens (30 vagas/imagem)\")\n",
    "        print(\"â€¢ Labels profissionais baseados em polÃ­gonos convertidos para YOLO\")\n",
    "        print(\"â€¢ Treinamento otimizado para dataset de qualidade superior\")\n",
    "        print(\"â€¢ DetecÃ§Ã£o precisa de vagas livres e ocupadas\")\n",
    "\n",
    "        print(\"\\nğŸ‰ SUCESSO TOTAL COM DATASET NOVO DE ALTA QUALIDADE! âœ“\")\n",
    "    else:\n",
    "        print(\"Projeto executado com limitaÃ§Ãµes\")\n",
    "\n",
    "print(\"\\n--- FunÃ§Ãµes definidas ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cMUEPUlg2Wi9",
    "outputId": "5411df6e-4945-4631-a940-3e88cfa62deb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando a execuÃ§Ã£o principal do projeto ---\n",
      "======================================================================\n",
      "TRABALHO FINAL - INTELIGENCIA ARTIFICIAL\n",
      "DetecÃ§Ã£o de Vagas de Estacionamento com YOLO\n",
      "VERSÃƒO FINAL - DATASET NOVO DE ALTA QUALIDADE\n",
      "903 anotaÃ§Ãµes precisas em 30 imagens\n",
      "======================================================================\n",
      "\n",
      "[1/6] Instalando dependÃªncias...\n",
      "âœ“ ultralytics==8.3.153\n",
      "âœ“ Pillow\n",
      "\n",
      "[2/6] Importando bibliotecas...\n",
      "âœ“ Todas as bibliotecas importadas\n",
      "\n",
      "[3/6] Configurando dataset YOLO novo (alta qualidade)...\n",
      "ğŸš— Configurando dataset YOLO novo (alta qualidade)...\n",
      "âœ… Dataset YOLO novo configurado: /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/dataset_yolo_novo\n",
      "ğŸ“„ Usando configuraÃ§Ã£o: /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/dataset_yolo_novo/data.yaml\n",
      "  ğŸ“‚ train: 21 imagens, 21 labels\n",
      "  ğŸ“‚ val: 4 imagens, 4 labels\n",
      "  ğŸ“‚ test: 5 imagens, 5 labels\n",
      "ğŸ“Š Total de anotaÃ§Ãµes: 903\n",
      "âœ… Dataset YOLO novo configurado com sucesso\n",
      "\n",
      "[4/6] Carregando modelo YOLO...\n",
      "âœ“ Modelo prÃ©-treinado yolov8n.pt carregado\n",
      "\n",
      "[5/6] Treinando modelo com dataset de alta qualidade...\n",
      "Iniciando treinamento (pode demorar alguns minutos)...\n",
      "ğŸ“Š Dataset: 903 anotaÃ§Ãµes precisas de vagas!\n",
      "Removendo treinamento anterior...\n",
      "Ultralytics 8.3.153 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/dataset_yolo_novo/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=150, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_vagas_novo, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=projeto_final_novo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=projeto_final_novo/yolo_vagas_novo, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 15.4MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.6Â±0.1 ms, read: 86.9Â±51.8 MB/s, size: 282.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/dataset_yolo_novo/train/labels... 21 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 75.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/dataset_yolo_novo/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 109.3Â±88.0 MB/s, size: 389.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/dataset_yolo_novo/val/labels... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 88.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/dataset_yolo_novo/val/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to projeto_final_novo/yolo_vagas_novo/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mprojeto_final_novo/yolo_vagas_novo\u001b[0m\n",
      "Starting training for 150 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/150         0G      1.628      3.361      1.459        209        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:27<00:00,  9.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123     0.0559      0.447       0.13     0.0803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/150         0G      1.398       2.78      1.239        278        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:26<00:00,  8.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123     0.0217       0.31      0.165     0.0943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/150         0G       1.21      1.892      1.119        267        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:29<00:00,  9.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.295      0.119      0.144     0.0712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/150         0G       1.29      1.578      1.143        445        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 2.200s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.683      0.208      0.128     0.0595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/150         0G      1.116      1.372      1.084        315        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.775      0.208      0.273      0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/150         0G      1.158      1.526      1.125        293        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.732      0.167      0.223      0.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/150         0G      1.042      1.332      1.065        498        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:23<00:00,  7.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.877       0.19      0.294       0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/150         0G      1.137      1.368      1.147        266        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 2.200s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.901      0.194      0.306      0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/150         0G      1.001      1.237      1.057        262        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.204      0.391      0.321      0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/150         0G     0.8603      1.393      1.068        174        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.815      0.327      0.418      0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/150         0G     0.8725      1.235       1.06        210        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.511      0.512      0.462      0.281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/150         0G      1.002      1.182      1.105        373        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.453      0.581      0.502      0.289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/150         0G       1.01       1.21      1.107        158        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:23<00:00,  7.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.473      0.593      0.547      0.327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/150         0G      1.105      1.275      1.101        318        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:25<00:00,  8.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.847      0.369      0.564       0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/150         0G     0.9114      1.103      1.009        325        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.847      0.369      0.564       0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/150         0G     0.9193      1.094     0.9788        350        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.342      0.625      0.513      0.272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/150         0G       1.07      1.176      1.071        363        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:24<00:00,  8.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.799      0.256      0.373      0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/150         0G      1.079      1.235       1.08        456        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.799      0.256      0.373      0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/150         0G     0.9773      1.106      1.057        228        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.799      0.265      0.373      0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/150         0G     0.9857       1.16      1.064        171        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:23<00:00,  7.90s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.606      0.514      0.505      0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/150         0G     0.9849      1.077      1.052        363        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.606      0.514      0.505      0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/150         0G     0.8397     0.9981      1.013        264        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.367      0.515      0.434      0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/150         0G     0.9691      1.025      1.061        319        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:23<00:00,  7.86s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.367      0.515      0.434      0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/150         0G     0.9842      1.068      1.061        203        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.351      0.545      0.362      0.215\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 14, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "24 epochs completed in 0.174 hours.\n",
      "Optimizer stripped from projeto_final_novo/yolo_vagas_novo/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from projeto_final_novo/yolo_vagas_novo/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating projeto_final_novo/yolo_vagas_novo/weights/best.pt...\n",
      "Ultralytics 8.3.153 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4        123      0.844      0.369      0.564       0.35\n",
      "    free_parking_space          4         39          1          0      0.414      0.261\n",
      "not_free_parking_space          4         84      0.688      0.738      0.713       0.44\n",
      "Speed: 2.3ms preprocess, 375.9ms inference, 0.0ms loss, 171.5ms postprocess per image\n",
      "Results saved to \u001b[1mprojeto_final_novo/yolo_vagas_novo\u001b[0m\n",
      "âœ“ Treinamento concluÃ­do! Resultados salvos em: projeto_final_novo/yolo_vagas_novo\n",
      "\n",
      "[6/6] Testando modelo...\n",
      "âœ“ Modelo treinado carregado: projeto_final_novo/yolo_vagas_novo/weights/best.pt\n",
      "Realizando inferÃªncia nas imagens de teste em: /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/dataset_yolo_novo/test/images\n",
      "Resultados serÃ£o salvos em: resultados_novo/predicoes_finais\n",
      "\n",
      "image 1/5 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/dataset_yolo_novo/test/images/14.png: 384x640 29 not_free_parking_spaces, 166.6ms\n",
      "image 2/5 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/dataset_yolo_novo/test/images/15.png: 448x640 4 free_parking_spaces, 60 not_free_parking_spaces, 190.7ms\n",
      "image 3/5 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/dataset_yolo_novo/test/images/19.png: 288x640 4 free_parking_spaces, 47 not_free_parking_spaces, 150.0ms\n",
      "image 4/5 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/dataset_yolo_novo/test/images/22.png: 384x640 52 not_free_parking_spaces, 151.9ms\n",
      "image 5/5 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/dataset_yolo_novo/test/images/28.png: 384x640 1 free_parking_space, 50 not_free_parking_spaces, 159.2ms\n",
      "Speed: 3.6ms preprocess, 163.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mresultados_novo/predicoes_finais\u001b[0m\n",
      "  ğŸ“¸ Imagem 1: 29 vagas detectadas\n",
      "    - Vaga 1: not_free_parking_space (confianÃ§a: 1.00)\n",
      "    - Vaga 2: not_free_parking_space (confianÃ§a: 0.92)\n",
      "    - Vaga 3: not_free_parking_space (confianÃ§a: 0.88)\n",
      "    - Vaga 4: not_free_parking_space (confianÃ§a: 0.86)\n",
      "    - Vaga 5: not_free_parking_space (confianÃ§a: 0.74)\n",
      "  ğŸ“¸ Imagem 2: 64 vagas detectadas\n",
      "    - Vaga 1: not_free_parking_space (confianÃ§a: 1.00)\n",
      "    - Vaga 2: not_free_parking_space (confianÃ§a: 1.00)\n",
      "    - Vaga 3: not_free_parking_space (confianÃ§a: 1.00)\n",
      "    - Vaga 4: not_free_parking_space (confianÃ§a: 1.00)\n",
      "    - Vaga 5: not_free_parking_space (confianÃ§a: 1.00)\n",
      "  ğŸ“¸ Imagem 3: 51 vagas detectadas\n",
      "    - Vaga 1: not_free_parking_space (confianÃ§a: 1.00)\n",
      "    - Vaga 2: not_free_parking_space (confianÃ§a: 1.00)\n",
      "    - Vaga 3: not_free_parking_space (confianÃ§a: 1.00)\n",
      "    - Vaga 4: not_free_parking_space (confianÃ§a: 1.00)\n",
      "    - Vaga 5: not_free_parking_space (confianÃ§a: 1.00)\n",
      "  ğŸ“¸ Imagem 4: 52 vagas detectadas\n",
      "  ğŸ“¸ Imagem 5: 51 vagas detectadas\n",
      "âœ“ Teste concluÃ­do! 5 imagens processadas.\n",
      "ğŸ“Š Total de detecÃ§Ãµes: 247\n",
      "\n",
      "============================================================\n",
      "ğŸš— TESTE FINAL COM IMAGENS DE INFERÃŠNCIA\n",
      "============================================================\n",
      "Realizando inferÃªncia final com dataset de alta qualidade em: /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia\n",
      "\n",
      "image 1/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-09-13_16_55_33.jpg: 384x640 23 not_free_parking_spaces, 156.3ms\n",
      "image 2/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-09-15_15_07_21.jpg: 384x640 10 not_free_parking_spaces, 166.1ms\n",
      "image 3/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-09-16_17_33_22.jpg: 384x640 9 not_free_parking_spaces, 159.9ms\n",
      "image 4/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-09-20_06_49_15.jpg: 384x640 9 not_free_parking_spaces, 159.3ms\n",
      "image 5/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-10-11_14_46_49.jpg: 384x640 61 not_free_parking_spaces, 157.2ms\n",
      "image 6/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-10-14_10_34_47 copy.jpg: 384x640 9 free_parking_spaces, 35 not_free_parking_spaces, 156.3ms\n",
      "image 7/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-10-14_10_34_47.jpg: 384x640 9 free_parking_spaces, 35 not_free_parking_spaces, 176.2ms\n",
      "image 8/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-10-26_10_04_36 copy.jpg: 384x640 68 not_free_parking_spaces, 155.9ms\n",
      "image 9/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-10-26_10_04_36.jpg: 384x640 68 not_free_parking_spaces, 158.3ms\n",
      "image 10/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-10-26_17_34_59 copy.jpg: 384x640 73 not_free_parking_spaces, 154.5ms\n",
      "image 11/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-10-26_17_34_59.jpg: 384x640 73 not_free_parking_spaces, 155.0ms\n",
      "image 12/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-10-26_18_45_02.jpg: 384x640 3 free_parking_spaces, 54 not_free_parking_spaces, 159.2ms\n",
      "image 13/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-10-27_09_00_43.jpg: 384x640 15 free_parking_spaces, 48 not_free_parking_spaces, 248.3ms\n",
      "image 14/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-10-28_17_12_16.jpg: 384x640 10 free_parking_spaces, 32 not_free_parking_spaces, 239.1ms\n",
      "image 15/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-10-30_16_27_22.jpg: 384x640 47 not_free_parking_spaces, 252.2ms\n",
      "image 16/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-11-06_14_53_34.jpg: 384x640 58 not_free_parking_spaces, 231.6ms\n",
      "image 17/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-11-08_17_40_56.jpg: 384x640 48 not_free_parking_spaces, 239.0ms\n",
      "image 18/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-11-10_10_42_50.jpg: 384x640 88 not_free_parking_spaces, 244.1ms\n",
      "image 19/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-11-20_18_24_42.jpg: 384x640 80 not_free_parking_spaces, 236.0ms\n",
      "image 20/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-12-17_13_05_09.jpg: 384x640 1 free_parking_space, 37 not_free_parking_spaces, 281.9ms\n",
      "image 21/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-12-18_16_45_13.jpg: 384x640 56 not_free_parking_spaces, 246.2ms\n",
      "image 22/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-12-22_09_45_05.jpg: 384x640 17 not_free_parking_spaces, 232.2ms\n",
      "image 23/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-12-24_13_15_08.jpg: 384x640 25 not_free_parking_spaces, 269.5ms\n",
      "image 24/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2012-12-28_10_05_05.jpg: 384x640 1 free_parking_space, 17 not_free_parking_spaces, 242.1ms\n",
      "image 25/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2013-01-16_12_15_08.jpg: 384x640 1 free_parking_space, 20 not_free_parking_spaces, 244.8ms\n",
      "image 26/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2013-01-16_13_25_09.jpg: 384x640 24 not_free_parking_spaces, 211.6ms\n",
      "image 27/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2013-01-17_15_15_11.jpg: 384x640 33 not_free_parking_spaces, 161.6ms\n",
      "image 28/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2013-03-09_08_15_02.jpg: 384x640 11 not_free_parking_spaces, 154.0ms\n",
      "image 29/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2013-03-12_10_30_05.jpg: 384x640 1 free_parking_space, 49 not_free_parking_spaces, 151.6ms\n",
      "image 30/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2013-03-18_12_30_07.jpg: 384x640 23 not_free_parking_spaces, 150.1ms\n",
      "image 31/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2013-03-19_11_35_06.jpg: 384x640 30 not_free_parking_spaces, 180.9ms\n",
      "image 32/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2013-04-15_07_25_01.jpg: 384x640 10 not_free_parking_spaces, 160.2ms\n",
      "image 33/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/2013-04-15_14_45_09.jpg: 384x640 37 not_free_parking_spaces, 160.1ms\n",
      "image 34/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_test_000.jpg: 384x640 47 not_free_parking_spaces, 160.9ms\n",
      "image 35/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_000.jpg: 384x640 23 not_free_parking_spaces, 156.9ms\n",
      "image 36/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_001.jpg: 384x640 10 not_free_parking_spaces, 177.1ms\n",
      "image 37/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_002.jpg: 384x640 9 not_free_parking_spaces, 149.9ms\n",
      "image 38/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_003.jpg: 384x640 9 not_free_parking_spaces, 152.4ms\n",
      "image 39/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_004.jpg: 384x640 61 not_free_parking_spaces, 155.4ms\n",
      "image 40/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_005.jpg: 384x640 9 free_parking_spaces, 35 not_free_parking_spaces, 157.8ms\n",
      "image 41/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_006.jpg: 384x640 68 not_free_parking_spaces, 162.9ms\n",
      "image 42/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_007.jpg: 384x640 73 not_free_parking_spaces, 150.7ms\n",
      "image 43/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_008.jpg: 384x640 3 free_parking_spaces, 54 not_free_parking_spaces, 154.3ms\n",
      "image 44/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_009.jpg: 384x640 15 free_parking_spaces, 48 not_free_parking_spaces, 158.0ms\n",
      "image 45/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_010.jpg: 384x640 10 free_parking_spaces, 32 not_free_parking_spaces, 186.4ms\n",
      "image 46/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_011.jpg: 384x640 47 not_free_parking_spaces, 174.1ms\n",
      "image 47/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_012.jpg: 384x640 58 not_free_parking_spaces, 155.5ms\n",
      "image 48/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_013.jpg: 384x640 48 not_free_parking_spaces, 156.5ms\n",
      "image 49/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_014.jpg: 384x640 88 not_free_parking_spaces, 177.6ms\n",
      "image 50/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_015.jpg: 384x640 80 not_free_parking_spaces, 156.6ms\n",
      "image 51/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_016.jpg: 384x640 1 free_parking_space, 37 not_free_parking_spaces, 152.0ms\n",
      "image 52/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_train_017.jpg: 384x640 56 not_free_parking_spaces, 172.9ms\n",
      "image 53/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_val_000.jpg: 384x640 17 not_free_parking_spaces, 174.1ms\n",
      "image 54/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_val_001.jpg: 384x640 25 not_free_parking_spaces, 152.8ms\n",
      "image 55/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_val_002.jpg: 384x640 1 free_parking_space, 17 not_free_parking_spaces, 165.4ms\n",
      "image 56/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_val_003.jpg: 384x640 1 free_parking_space, 20 not_free_parking_spaces, 155.1ms\n",
      "image 57/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_val_004.jpg: 384x640 24 not_free_parking_spaces, 169.8ms\n",
      "image 58/58 /content/drive/MyDrive/IA_Projeto_Final/trabalho_inteligencia_artificial/trabalho_inteligencia_artificial/imagens_para_inferencia/parking_val_005.jpg: 384x640 33 not_free_parking_spaces, 171.3ms\n",
      "Speed: 3.3ms preprocess, 181.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mteste_final_novo/inferencia_final\u001b[0m\n",
      "  ğŸ“¸ 2012-09-13_16_55_33.jpg: 23 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 23\n",
      "  ğŸ“¸ 2012-09-15_15_07_21.jpg: 10 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 10\n",
      "  ğŸ“¸ 2012-09-16_17_33_22.jpg: 9 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 9\n",
      "  ğŸ“¸ 2012-09-20_06_49_15.jpg: 9 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 9\n",
      "  ğŸ“¸ 2012-10-11_14_46_49.jpg: 61 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 61\n",
      "  ğŸ“¸ 2012-10-14_10_34_47 copy.jpg: 44 vagas\n",
      "    ğŸŸ¢ Livres: 9 | ğŸ”´ Ocupadas: 35\n",
      "  ğŸ“¸ 2012-10-14_10_34_47.jpg: 44 vagas\n",
      "    ğŸŸ¢ Livres: 9 | ğŸ”´ Ocupadas: 35\n",
      "  ğŸ“¸ 2012-10-26_10_04_36 copy.jpg: 68 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 68\n",
      "  ğŸ“¸ 2012-10-26_10_04_36.jpg: 68 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 68\n",
      "  ğŸ“¸ 2012-10-26_17_34_59 copy.jpg: 73 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 73\n",
      "  ğŸ“¸ 2012-10-26_17_34_59.jpg: 73 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 73\n",
      "  ğŸ“¸ 2012-10-26_18_45_02.jpg: 57 vagas\n",
      "    ğŸŸ¢ Livres: 3 | ğŸ”´ Ocupadas: 54\n",
      "  ğŸ“¸ 2012-10-27_09_00_43.jpg: 63 vagas\n",
      "    ğŸŸ¢ Livres: 15 | ğŸ”´ Ocupadas: 48\n",
      "  ğŸ“¸ 2012-10-28_17_12_16.jpg: 42 vagas\n",
      "    ğŸŸ¢ Livres: 10 | ğŸ”´ Ocupadas: 32\n",
      "  ğŸ“¸ 2012-10-30_16_27_22.jpg: 47 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 47\n",
      "  ğŸ“¸ 2012-11-06_14_53_34.jpg: 58 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 58\n",
      "  ğŸ“¸ 2012-11-08_17_40_56.jpg: 48 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 48\n",
      "  ğŸ“¸ 2012-11-10_10_42_50.jpg: 88 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 88\n",
      "  ğŸ“¸ 2012-11-20_18_24_42.jpg: 80 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 80\n",
      "  ğŸ“¸ 2012-12-17_13_05_09.jpg: 38 vagas\n",
      "    ğŸŸ¢ Livres: 1 | ğŸ”´ Ocupadas: 37\n",
      "  ğŸ“¸ 2012-12-18_16_45_13.jpg: 56 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 56\n",
      "  ğŸ“¸ 2012-12-22_09_45_05.jpg: 17 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 17\n",
      "  ğŸ“¸ 2012-12-24_13_15_08.jpg: 25 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 25\n",
      "  ğŸ“¸ 2012-12-28_10_05_05.jpg: 18 vagas\n",
      "    ğŸŸ¢ Livres: 1 | ğŸ”´ Ocupadas: 17\n",
      "  ğŸ“¸ 2013-01-16_12_15_08.jpg: 21 vagas\n",
      "    ğŸŸ¢ Livres: 1 | ğŸ”´ Ocupadas: 20\n",
      "  ğŸ“¸ 2013-01-16_13_25_09.jpg: 24 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 24\n",
      "  ğŸ“¸ 2013-01-17_15_15_11.jpg: 33 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 33\n",
      "  ğŸ“¸ 2013-03-09_08_15_02.jpg: 11 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 11\n",
      "  ğŸ“¸ 2013-03-12_10_30_05.jpg: 50 vagas\n",
      "    ğŸŸ¢ Livres: 1 | ğŸ”´ Ocupadas: 49\n",
      "  ğŸ“¸ 2013-03-18_12_30_07.jpg: 23 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 23\n",
      "  ğŸ“¸ 2013-03-19_11_35_06.jpg: 30 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 30\n",
      "  ğŸ“¸ 2013-04-15_07_25_01.jpg: 10 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 10\n",
      "  ğŸ“¸ 2013-04-15_14_45_09.jpg: 37 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 37\n",
      "  ğŸ“¸ parking_test_000.jpg: 47 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 47\n",
      "  ğŸ“¸ parking_train_000.jpg: 23 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 23\n",
      "  ğŸ“¸ parking_train_001.jpg: 10 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 10\n",
      "  ğŸ“¸ parking_train_002.jpg: 9 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 9\n",
      "  ğŸ“¸ parking_train_003.jpg: 9 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 9\n",
      "  ğŸ“¸ parking_train_004.jpg: 61 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 61\n",
      "  ğŸ“¸ parking_train_005.jpg: 44 vagas\n",
      "    ğŸŸ¢ Livres: 9 | ğŸ”´ Ocupadas: 35\n",
      "  ğŸ“¸ parking_train_006.jpg: 68 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 68\n",
      "  ğŸ“¸ parking_train_007.jpg: 73 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 73\n",
      "  ğŸ“¸ parking_train_008.jpg: 57 vagas\n",
      "    ğŸŸ¢ Livres: 3 | ğŸ”´ Ocupadas: 54\n",
      "  ğŸ“¸ parking_train_009.jpg: 63 vagas\n",
      "    ğŸŸ¢ Livres: 15 | ğŸ”´ Ocupadas: 48\n",
      "  ğŸ“¸ parking_train_010.jpg: 42 vagas\n",
      "    ğŸŸ¢ Livres: 10 | ğŸ”´ Ocupadas: 32\n",
      "  ğŸ“¸ parking_train_011.jpg: 47 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 47\n",
      "  ğŸ“¸ parking_train_012.jpg: 58 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 58\n",
      "  ğŸ“¸ parking_train_013.jpg: 48 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 48\n",
      "  ğŸ“¸ parking_train_014.jpg: 88 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 88\n",
      "  ğŸ“¸ parking_train_015.jpg: 80 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 80\n",
      "  ğŸ“¸ parking_train_016.jpg: 38 vagas\n",
      "    ğŸŸ¢ Livres: 1 | ğŸ”´ Ocupadas: 37\n",
      "  ğŸ“¸ parking_train_017.jpg: 56 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 56\n",
      "  ğŸ“¸ parking_val_000.jpg: 17 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 17\n",
      "  ğŸ“¸ parking_val_001.jpg: 25 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 25\n",
      "  ğŸ“¸ parking_val_002.jpg: 18 vagas\n",
      "    ğŸŸ¢ Livres: 1 | ğŸ”´ Ocupadas: 17\n",
      "  ğŸ“¸ parking_val_003.jpg: 21 vagas\n",
      "    ğŸŸ¢ Livres: 1 | ğŸ”´ Ocupadas: 20\n",
      "  ğŸ“¸ parking_val_004.jpg: 24 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 24\n",
      "  ğŸ“¸ parking_val_005.jpg: 33 vagas\n",
      "    ğŸŸ¢ Livres: 0 | ğŸ”´ Ocupadas: 33\n",
      "\n",
      "âœ“ InferÃªncia final concluÃ­da! 58 imagens processadas.\n",
      "ğŸ“ Resultados salvos em: teste_final_novo/inferencia_final/\n",
      "ğŸ“Š Total de detecÃ§Ãµes: 2417\n",
      "\n",
      "======================================================================\n",
      "PROJETO CONCLUÃDO COM DATASET DE ALTA QUALIDADE!\n",
      "======================================================================\n",
      "Tempo total: 11.3 minutos\n",
      "\n",
      "Arquivos criados:\n",
      "âœ“ dataset_yolo_novo/ - Dataset de alta qualidade (903 anotaÃ§Ãµes)\n",
      "âœ“ projeto_final_novo/ - Modelo treinado\n",
      "âœ“ resultados_novo/ - PrediÃ§Ãµes do teste\n",
      "âœ“ teste_final_novo/ - InferÃªncia final\n",
      "\n",
      "Este projeto demonstra:\n",
      "â€¢ Uso de dataset de ALTA QUALIDADE com anotaÃ§Ãµes manuais precisas\n",
      "â€¢ 903 anotaÃ§Ãµes de vagas em 30 imagens (30 vagas/imagem)\n",
      "â€¢ Labels profissionais baseados em polÃ­gonos convertidos para YOLO\n",
      "â€¢ Treinamento otimizado para dataset de qualidade superior\n",
      "â€¢ DetecÃ§Ã£o precisa de vagas livres e ocupadas\n",
      "\n",
      "ğŸ‰ SUCESSO TOTAL COM DATASET NOVO DE ALTA QUALIDADE! âœ“\n",
      "\n",
      "--- ExecuÃ§Ã£o principal concluÃ­da ---\n"
     ]
    }
   ],
   "source": [
    "# CÃ©lula 4: ExecuÃ§Ã£o do Script Principal\n",
    "print(\"--- Iniciando a execuÃ§Ã£o principal do projeto ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "print(\"\\n--- ExecuÃ§Ã£o principal concluÃ­da ---\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
