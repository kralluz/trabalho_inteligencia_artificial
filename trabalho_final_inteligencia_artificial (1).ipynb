{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zcmFrwX1fpR",
        "outputId": "1fde755e-a2a9-43d4-f611-3b3c01bff985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Configurando ambiente Google Colab com GitHub ---\n",
            "Clonando repositÃ³rio: https://github.com/kralluz/trabalho_inteligencia_artificial.git...\n",
            "Cloning into 'trabalho_inteligencia_artificial'...\n",
            "remote: Enumerating objects: 804, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 804 (delta 0), reused 1 (delta 0), pack-reused 801 (from 2)\u001b[K\n",
            "Receiving objects: 100% (804/804), 325.45 MiB | 28.99 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n",
            "Updating files: 100% (210/210), done.\n",
            "DiretÃ³rio de trabalho atual: /content/trabalho_inteligencia_artificial\n",
            "\n",
            "Verificando conteÃºdo do diretÃ³rio do projeto (primeiros 5 itens):\n",
            "- projeto_final_novo\n",
            "- .git\n",
            "- imagens_para_inferencia\n",
            "- yolov8n.pt\n",
            "- dataset_novo\n",
            "... e mais 5 itens.\n",
            "\n",
            "--- ConfiguraÃ§Ã£o inicial e clone do GitHub concluÃ­dos ---\n"
          ]
        }
      ],
      "source": [
        "# CÃ©lula 1: Clonar o RepositÃ³rio GitHub e Mudar para o DiretÃ³rio do Projeto\n",
        "import os\n",
        "import shutil  # OperaÃ§Ãµes de cÃ³pia e movimentaÃ§Ã£o de arquivos\n",
        "import subprocess  # ExecuÃ§Ã£o de comandos externos\n",
        "import sys  # Acesso ao sistema e argumentos da linha de comando\n",
        "import time\n",
        "import traceback  # ExibiÃ§Ã£o detalhada de erros e exceÃ§Ãµes\n",
        "\n",
        "import numpy as np  # OperaÃ§Ãµes matemÃ¡ticas e manipulaÃ§Ã£o de arrays\n",
        "import torch  # Processamento e inferÃªncia com modelos PyTorch\n",
        "from PIL import Image  # ManipulaÃ§Ã£o de imagens\n",
        "from ultralytics import YOLO  # Uso do modelo YOLO para detecÃ§Ã£o de objetos\n",
        "\n",
        "print(\"--- Configurando ambiente Google Colab com GitHub ---\")\n",
        "\n",
        "# --- PARÃ‚METROS DO SEU REPOSITÃ“RIO ---\n",
        "# URL do seu repositÃ³rio GitHub\n",
        "GIT_REPO_URL = 'https://github.com/kralluz/trabalho_inteligencia_artificial.git'\n",
        "\n",
        "# Nome da pasta do repositÃ³rio apÃ³s o clone (geralmente o nome do repositÃ³rio)\n",
        "REPO_NAME = 'trabalho_inteligencia_artificial'\n",
        "# -----------------------------------\n",
        "\n",
        "# Clonar o repositÃ³rio\n",
        "print(f\"Clonando repositÃ³rio: {GIT_REPO_URL}...\")\n",
        "if os.path.exists(REPO_NAME):\n",
        "    print(f\"DiretÃ³rio '{REPO_NAME}' jÃ¡ existe. Removendo para clonar novamente...\")\n",
        "    !rm -rf {REPO_NAME}\n",
        "!git clone {GIT_REPO_URL}\n",
        "\n",
        "# Mudar o diretÃ³rio de trabalho para a raiz do repositÃ³rio clonado\n",
        "# Isso Ã© crucial para que os caminhos relativos no seu script funcionem\n",
        "os.chdir(REPO_NAME)\n",
        "print(f\"DiretÃ³rio de trabalho atual: {os.getcwd()}\")\n",
        "\n",
        "print(\"\\nVerificando conteÃºdo do diretÃ³rio do projeto (primeiros 5 itens):\")\n",
        "try:\n",
        "    listed_items = os.listdir('.')\n",
        "    for i, item in enumerate(listed_items[:5]):\n",
        "        print(f\"- {item}\")\n",
        "    if len(listed_items) > 5:\n",
        "        print(f\"... e mais {len(listed_items) - 5} itens.\")\n",
        "    elif not listed_items:\n",
        "        print(\"O diretÃ³rio do projeto parece estar vazio apÃ³s o clone.\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao listar o diretÃ³rio: {e}\")\n",
        "\n",
        "print(\"\\n--- ConfiguraÃ§Ã£o inicial e clone do GitHub concluÃ­dos ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÃ©lula 2: InstalaÃ§Ã£o de DependÃªncias\n",
        "print(\"--- [1/6] Instalando dependÃªncias... ---\")\n",
        "\n",
        "deps = [\n",
        "    \"pip install ultralytics==8.3.153 --quiet\",\n",
        "    \"pip install Pillow numpy matplotlib --quiet\"\n",
        "]\n",
        "\n",
        "for dep in deps:\n",
        "    try:\n",
        "        print(f\"Executando: {dep}\")\n",
        "        # Usamos '!' para executar comandos de shell diretamente no Colab\n",
        "        !{dep}\n",
        "        print(f\"âœ“ {dep.split()[2]} instalado/verificado.\")\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Erro ao instalar {dep.split()[2]}: {e}\")\n",
        "        print(f\"~ {dep.split()[2]} (pode jÃ¡ estar instalado ou houve outro problema).\")\n",
        "\n",
        "print(\"\\n--- InstalaÃ§Ã£o de dependÃªncias concluÃ­da ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLEHpFBE13Y6",
        "outputId": "f264e09a-efc1-4fac-8012-7864497012de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- [1/6] Instalando dependÃªncias... ---\n",
            "Executando: pip install ultralytics==8.3.153 --quiet\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ“ ultralytics==8.3.153 instalado/verificado.\n",
            "Executando: pip install Pillow numpy matplotlib --quiet\n",
            "âœ“ Pillow instalado/verificado.\n",
            "\n",
            "--- InstalaÃ§Ã£o de dependÃªncias concluÃ­da ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÃ©lula 3: DefiniÃ§Ã£o da FunÃ§Ã£o 'configurar_dataset_novo()'\n",
        "\n",
        "print(\"--- Definindo a funÃ§Ã£o 'configurar_dataset_novo()' ---\")\n",
        "\n",
        "def configurar_dataset_novo():\n",
        "    \"\"\"Configura o dataset YOLO novo (convertido com alta qualidade)\"\"\"\n",
        "    print(\"ğŸš— Configurando dataset YOLO novo (alta qualidade)...\")\n",
        "\n",
        "    base_path = os.getcwd()\n",
        "    dataset_path = os.path.join(base_path, \"dataset_yolo_novo\")\n",
        "    yaml_path = os.path.join(dataset_path, \"data.yaml\")\n",
        "\n",
        "    # Verificar se o dataset existe\n",
        "    if not os.path.exists(dataset_path):\n",
        "        print(\"âŒ Dataset YOLO novo nÃ£o encontrado!\")\n",
        "        print(\"ğŸ’¡ Certifique-se de que 'dataset_yolo_novo' estÃ¡ na raiz do seu repositÃ³rio GitHub.\")\n",
        "        return None\n",
        "\n",
        "    if not os.path.exists(yaml_path):\n",
        "        print(\"âŒ Arquivo data.yaml nÃ£o encontrado!\")\n",
        "        print(f\"ğŸ’¡ Certifique-se de que '{yaml_path}' existe no seu repositÃ³rio GitHub.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"âœ… Dataset YOLO novo configurado: {dataset_path}\")\n",
        "    print(f\"ğŸ“„ Usando configuraÃ§Ã£o: {yaml_path}\")\n",
        "\n",
        "    # Verificar estrutura do dataset\n",
        "    total_annotations = 0\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        img_dir = os.path.join(dataset_path, split, 'images')\n",
        "        lbl_dir = os.path.join(dataset_path, split, 'labels')\n",
        "\n",
        "        if os.path.exists(img_dir) and os.path.exists(lbl_dir):\n",
        "            img_count = len([f for f in os.listdir(img_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "            lbl_count = len([f for f in os.listdir(lbl_dir) if f.lower().endswith('.txt')])\n",
        "\n",
        "            # Contar anotaÃ§Ãµes\n",
        "            for lbl_file in os.listdir(lbl_dir):\n",
        "                if lbl_file.lower().endswith('.txt'):\n",
        "                    lbl_path = os.path.join(lbl_dir, lbl_file)\n",
        "                    with open(lbl_path, 'r') as f:\n",
        "                        total_annotations += len(f.readlines())\n",
        "\n",
        "            print(f\"  ğŸ“‚ {split}: {img_count} imagens, {lbl_count} labels\")\n",
        "        else:\n",
        "            print(f\"  âš ï¸ {split}: diretÃ³rio '{split}' nÃ£o encontrado ou incompleto em {dataset_path}\")\n",
        "\n",
        "    print(f\"ğŸ“Š Total de anotaÃ§Ãµes: {total_annotations}\")\n",
        "    return yaml_path\n",
        "\n",
        "print(\"\\n--- FunÃ§Ã£o 'configurar_dataset_novo()' definida ---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhQujC-i16h7",
        "outputId": "fb1a6aa7-a1dd-4f0e-9e7f-14cb8ee0fb1b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Definindo a funÃ§Ã£o 'configurar_dataset_novo()' ---\n",
            "\n",
            "--- FunÃ§Ã£o 'configurar_dataset_novo()' definida ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÃ©lula 4: InÃ­cio da FunÃ§Ã£o 'main()' - ImportaÃ§Ãµes e ConfiguraÃ§Ã£o do Dataset\n",
        "\n",
        "# Bloco de inicializaÃ§Ã£o da funÃ§Ã£o main()\n",
        "print(\"=\" * 70)\n",
        "print(\"TRABALHO FINAL - INTELIGENCIA ARTIFICIAL\")\n",
        "print(\"DetecÃ§Ã£o de Vagas de Estacionamento com YOLO\")\n",
        "print(\"VERSÃƒO FINAL - DATASET NOVO DE ALTA QUALIDADE\")\n",
        "print(\"903 anotaÃ§Ãµes precisas em 30 imagens\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "start_time = time.time() # Inicia a contagem de tempo\n",
        "\n",
        "print(\"\\n[2/6] Importando bibliotecas...\")\n",
        "try:\n",
        "    # As importaÃ§Ãµes jÃ¡ estÃ£o no topo da cÃ©lula\n",
        "    print(\"âœ“ Todas as bibliotecas importadas\")\n",
        "except ImportError as e:\n",
        "    print(f\"âœ— Erro de importaÃ§Ã£o: {e}\")\n",
        "    # sys.exit(1) # Pode adicionar um sys.exit(1) para parar a execuÃ§Ã£o em caso de erro fatal\n",
        "\n",
        "print(\"\\n[3/6] Configurando dataset YOLO novo (alta qualidade)...\")\n",
        "try:\n",
        "    # Chama a funÃ§Ã£o definida na CÃ©lula 3\n",
        "    yaml_path = configurar_dataset_novo()\n",
        "    if yaml_path:\n",
        "        print(\"âœ… Dataset YOLO novo configurado com sucesso\")\n",
        "    else:\n",
        "        print(\"âŒ Erro ao configurar dataset YOLO novo\")\n",
        "        # sys.exit(1) # Pode adicionar um sys.exit(1) para parar a execuÃ§Ã£o em caso de erro fatal\n",
        "except Exception as e:\n",
        "    print(f\"âœ— Erro ao configurar dataset: {e}\")\n",
        "    # sys.exit(1) # Pode adicionar um sys.exit(1) para parar a execuÃ§Ã£o em caso de erro fatal\n",
        "\n",
        "print(\"\\n[4/6] Carregando modelo YOLO...\")\n",
        "try:\n",
        "    # Tentar carregar modelo prÃ©-treinado\n",
        "    try:\n",
        "        model = YOLO('yolov8n.pt')\n",
        "        print(\"âœ“ Modelo prÃ©-treinado yolov8n.pt carregado\")\n",
        "    except Exception as e1:\n",
        "        print(f\"~ NÃ£o foi possÃ­vel carregar yolov8n.pt ({e1}), tentando yolov8n.yaml...\")\n",
        "        try:\n",
        "            model = YOLO('yolov8n.yaml')\n",
        "            print(\"âœ“ Modelo criado do zero a partir de yolov8n.yaml\")\n",
        "        except Exception as e2:\n",
        "            print(f\"âœ— Erro ao criar modelo com yolov8n.yaml: {e2}\")\n",
        "            # sys.exit(1) # Pode adicionar um sys.exit(1)\n",
        "except Exception as e:\n",
        "    print(f\"âœ— Erro fatal ao carregar/criar modelo: {e}\")\n",
        "    # sys.exit(1) # Pode adicionar um sys.exit(1)\n",
        "\n",
        "# As variÃ¡veis 'model' e 'yaml_path' precisam ser acessÃ­veis nas prÃ³ximas cÃ©lulas.\n",
        "# Em notebooks, variÃ¡veis definidas em uma cÃ©lula sÃ£o acessÃ­veis nas seguintes.\n",
        "print(\"\\n--- ImportaÃ§Ãµes e ConfiguraÃ§Ã£o do Dataset concluÃ­das ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMUEPUlg2Wi9",
        "outputId": "c0b1410e-0986-45c3-9908-7b884d81039a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "TRABALHO FINAL - INTELIGENCIA ARTIFICIAL\n",
            "DetecÃ§Ã£o de Vagas de Estacionamento com YOLO\n",
            "VERSÃƒO FINAL - DATASET NOVO DE ALTA QUALIDADE\n",
            "903 anotaÃ§Ãµes precisas em 30 imagens\n",
            "======================================================================\n",
            "\n",
            "[2/6] Importando bibliotecas...\n",
            "âœ“ Todas as bibliotecas importadas\n",
            "\n",
            "[3/6] Configurando dataset YOLO novo (alta qualidade)...\n",
            "ğŸš— Configurando dataset YOLO novo (alta qualidade)...\n",
            "âœ… Dataset YOLO novo configurado: /content/trabalho_inteligencia_artificial/dataset_yolo_novo\n",
            "ğŸ“„ Usando configuraÃ§Ã£o: /content/trabalho_inteligencia_artificial/dataset_yolo_novo/data.yaml\n",
            "  ğŸ“‚ train: 21 imagens, 21 labels\n",
            "  ğŸ“‚ val: 4 imagens, 4 labels\n",
            "  ğŸ“‚ test: 5 imagens, 5 labels\n",
            "ğŸ“Š Total de anotaÃ§Ãµes: 903\n",
            "âœ… Dataset YOLO novo configurado com sucesso\n",
            "\n",
            "[4/6] Carregando modelo YOLO...\n",
            "âœ“ Modelo prÃ©-treinado yolov8n.pt carregado\n",
            "\n",
            "--- ImportaÃ§Ãµes e ConfiguraÃ§Ã£o do Dataset concluÃ­das ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÃ©lula 5: Treinamento do Modelo\n",
        "print(\"--- [5/6] Treinando modelo com dataset de alta qualidade... ---\")\n",
        "\n",
        "try:\n",
        "    print(\"Iniciando treinamento (pode demorar alguns minutos)...\")\n",
        "    print(\"ğŸ“Š Dataset: 903 anotaÃ§Ãµes precisas de vagas!\")\n",
        "\n",
        "    # Limpar projetos anteriores\n",
        "    if os.path.exists('projeto_final_novo'):\n",
        "        print(\"Removendo treinamento anterior...\")\n",
        "        shutil.rmtree('projeto_final_novo')\n",
        "\n",
        "    # ConfiguraÃ§Ãµes de treinamento otimizadas para o novo dataset\n",
        "    results = model.train( # 'model' e 'yaml_path' sÃ£o acessÃ­veis da CÃ©lula 4\n",
        "        data=yaml_path,\n",
        "        epochs=150,           # Menos Ã©pocas pois o dataset Ã© de alta qualidade\n",
        "        batch=8,              # Batch maior pois temos menos imagens mas mais anotaÃ§Ãµes\n",
        "        imgsz=640,            # ResoluÃ§Ã£o maior para melhor precisÃ£o\n",
        "        device='cpu',         # Mantenha 'cpu' ou mude para '0'/'cuda' se for usar GPU\n",
        "        project='projeto_final_novo',\n",
        "        name='yolo_vagas_novo',\n",
        "        exist_ok=True,\n",
        "        pretrained=True,\n",
        "        optimizer='AdamW',    # Otimizador mais moderno\n",
        "        verbose=True,\n",
        "        seed=42,\n",
        "        deterministic=True,\n",
        "        patience=10,          # Early stopping mais agressivo\n",
        "        save_period=5,        # Salvar checkpoints a cada 5 Ã©pocas\n",
        "        val=True,\n",
        "        cache=False,\n",
        "        lr0=0.01,             # Learning rate inicial\n",
        "        warmup_epochs=3       # Warmup epochs\n",
        "    )\n",
        "    print(f\"âœ“ Treinamento concluÃ­do! Resultados salvos em: {results.save_dir}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âœ— Erro no treinamento: {e}\")\n",
        "    print(\"Detalhes do erro:\")\n",
        "    traceback.print_exc()\n",
        "    print(\"Continuando com validaÃ§Ã£o...\")\n",
        "\n",
        "print(\"\\n--- Treinamento do modelo concluÃ­do ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXgbmIOx_he_",
        "outputId": "968964b9-c1af-4877-ec37-395695e531d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- [5/6] Treinando modelo com dataset de alta qualidade... ---\n",
            "Iniciando treinamento (pode demorar alguns minutos)...\n",
            "ğŸ“Š Dataset: 903 anotaÃ§Ãµes precisas de vagas!\n",
            "Removendo treinamento anterior...\n",
            "New https://pypi.org/project/ultralytics/8.3.154 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.153 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/trabalho_inteligencia_artificial/dataset_yolo_novo/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=150, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_vagas_novo, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=projeto_final_novo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=projeto_final_novo/yolo_vagas_novo, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1579.9Â±946.0 MB/s, size: 282.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/trabalho_inteligencia_artificial/dataset_yolo_novo/train/labels.cache... 21 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1619.9Â±676.1 MB/s, size: 389.1 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/trabalho_inteligencia_artificial/dataset_yolo_novo/val/labels.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to projeto_final_novo/yolo_vagas_novo/labels.jpg... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mprojeto_final_novo/yolo_vagas_novo\u001b[0m\n",
            "Starting training for 150 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/150         0G      1.462      3.404      1.348        333        640:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:08<00:17,  8.87s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÃ©lula 6: Testes e InferÃªncia Final\n",
        "print(\"--- [6/6] Testando modelo e realizando inferÃªncia final... ---\")\n",
        "\n",
        "model_path_best = os.path.join('projeto_final_novo', 'yolo_vagas_novo', 'weights', 'best.pt')\n",
        "model_path_last = os.path.join('projeto_final_novo', 'yolo_vagas_novo', 'weights', 'last.pt')\n",
        "\n",
        "loaded_model = None\n",
        "if os.path.exists(model_path_best):\n",
        "    try:\n",
        "        loaded_model = YOLO(model_path_best)\n",
        "        print(f\"âœ“ Modelo treinado carregado: {model_path_best}\")\n",
        "    except Exception as e_best:\n",
        "        print(f\"~ Problema ao carregar best.pt ({e_best}), tentando last.pt...\")\n",
        "        if os.path.exists(model_path_last):\n",
        "            try:\n",
        "                loaded_model = YOLO(model_path_last)\n",
        "                print(f\"âœ“ Modelo treinado carregado: {model_path_last}\")\n",
        "            except Exception as e_last:\n",
        "                print(f\"~ Erro ao carregar last.pt ({e_last}). Teste abortado.\")\n",
        "elif os.path.exists(model_path_last):\n",
        "    try:\n",
        "        loaded_model = YOLO(model_path_last)\n",
        "        print(f\"âœ“ Modelo treinado carregado: {model_path_last}\")\n",
        "    except Exception as e_last:\n",
        "        print(f\"~ Erro ao carregar last.pt ({e_last}). Teste abortado.\")\n",
        "else:\n",
        "    print(\"~ Nenhum modelo treinado encontrado. Teste abortado.\")\n",
        "\n",
        "if loaded_model:\n",
        "    try:\n",
        "        # DiretÃ³rio de teste\n",
        "        test_images_dir = os.path.join(os.path.dirname(yaml_path), 'test', 'images')\n",
        "\n",
        "        # Criar diretÃ³rio para resultados da inferÃªncia\n",
        "        results_dir = \"resultados_novo/predicoes_finais\"\n",
        "        os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"Realizando inferÃªncia nas imagens de teste em: {test_images_dir}\")\n",
        "        print(f\"Resultados serÃ£o salvos em: {results_dir}\")\n",
        "\n",
        "        results_pred = loaded_model.predict(\n",
        "            source=test_images_dir,\n",
        "            save=True,\n",
        "            project=\"resultados_novo\",\n",
        "            name=\"predicoes_finais\",\n",
        "            exist_ok=True,\n",
        "            conf=0.1,   # ConfianÃ§a mais baixa para capturar mais detecÃ§Ãµes\n",
        "            iou=0.5,    # IoU para NMS\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        # Analisar resultados detalhadamente\n",
        "        total_detections = 0\n",
        "        for i, result in enumerate(results_pred):\n",
        "            if result.boxes is not None and len(result.boxes) > 0:\n",
        "                detections = len(result.boxes)\n",
        "                total_detections += detections\n",
        "                print(f\"  ğŸ“¸ Imagem {i+1}: {detections} vagas detectadas\")\n",
        "\n",
        "                if i < 3:  # Mostrar detalhes das 3 primeiras imagens\n",
        "                    for j, box in enumerate(result.boxes[:5]):  # Max 5 detecÃ§Ãµes por imagem\n",
        "                        cls = int(box.cls[0])\n",
        "                        conf = float(box.conf[0])\n",
        "                        class_name = loaded_model.names[cls]\n",
        "                        print(f\"    - Vaga {j+1}: {class_name} (confianÃ§a: {conf:.2f})\")\n",
        "            else:\n",
        "                print(f\"  ğŸ“¸ Imagem {i+1}: 0 vagas detectadas\")\n",
        "\n",
        "        print(f\"âœ“ Teste concluÃ­do! {len(results_pred)} imagens processadas.\")\n",
        "        print(f\"ğŸ“Š Total de detecÃ§Ãµes: {total_detections}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"~ Erro no teste: {e}\")\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"~ Modelo nÃ£o carregado, pulando etapa de teste.\")\n",
        "\n",
        "# Teste final com imagens para inferÃªncia\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸš— TESTE FINAL COM IMAGENS DE INFERÃŠNCIA\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "inference_images_path = os.path.join(os.getcwd(), 'imagens_para_inferencia')\n",
        "\n",
        "if loaded_model and os.path.exists(inference_images_path):\n",
        "    try:\n",
        "        print(f\"Realizando inferÃªncia final com dataset de alta qualidade em: {inference_images_path}\")\n",
        "\n",
        "        inference_results = loaded_model.predict(\n",
        "            source=inference_images_path,\n",
        "            save=True,\n",
        "            project='teste_final_novo',\n",
        "            name='inferencia_final',\n",
        "            exist_ok=True,\n",
        "            conf=0.1,   # ConfianÃ§a baixa para capturar mais detecÃ§Ãµes\n",
        "            iou=0.5,\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        # Analisar resultados da inferÃªncia final\n",
        "        total_detections = 0\n",
        "        for result in inference_results:\n",
        "            if result.boxes is not None:\n",
        "                detections = len(result.boxes)\n",
        "                total_detections += detections\n",
        "\n",
        "                # Analisar por classe\n",
        "                free_count = 0\n",
        "                occupied_count = 0\n",
        "\n",
        "                for box in result.boxes:\n",
        "                    cls = int(box.cls[0])\n",
        "                    conf = float(box.conf[0])\n",
        "\n",
        "                    if loaded_model.names[cls] == 'free_parking_space':\n",
        "                        free_count += 1\n",
        "                    elif loaded_model.names[cls] == 'not_free_parking_space':\n",
        "                        occupied_count += 1\n",
        "\n",
        "                print(f\"  ğŸ“¸ {os.path.basename(result.path)}: {detections} vagas\")\n",
        "                print(f\"    ğŸŸ¢ Livres: {free_count} | ğŸ”´ Ocupadas: {occupied_count}\")\n",
        "            else:\n",
        "                print(f\"  ğŸ“¸ {os.path.basename(result.path)}: 0 vagas detectadas\")\n",
        "\n",
        "        print(f\"\\nâœ“ InferÃªncia final concluÃ­da! {len(inference_results)} imagens processadas.\")\n",
        "        print(f\"ğŸ“ Resultados salvos em: teste_final_novo/inferencia_final/\")\n",
        "        print(f\"ğŸ“Š Total de detecÃ§Ãµes: {total_detections}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Erro na inferÃªncia final: {e}\")\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"~ DiretÃ³rio 'imagens_para_inferencia' nÃ£o encontrado ou modelo nÃ£o carregado. Pulando inferÃªncia final.\")\n",
        "\n",
        "# Resumo final\n",
        "end_time = time.time() # A variÃ¡vel start_time Ã© do inÃ­cio da CÃ©lula 4\n",
        "duration = (end_time - start_time) / 60\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PROJETO CONCLUÃDO COM DATASET DE ALTA QUALIDADE!\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Tempo total: {duration:.1f} minutos\")\n",
        "\n",
        "if os.path.exists('projeto_final_novo'):\n",
        "    print(\"\\nArquivos criados:\")\n",
        "    print(\"âœ“ dataset_yolo_novo/ - Dataset de alta qualidade (903 anotaÃ§Ãµes)\")\n",
        "    print(\"âœ“ projeto_final_novo/ - Modelo treinado\")\n",
        "    if os.path.exists('resultados_novo'):\n",
        "        print(\"âœ“ resultados_novo/ - PrediÃ§Ãµes do teste\")\n",
        "    if os.path.exists('teste_final_novo'):\n",
        "        print(\"âœ“ teste_final_novo/ - InferÃªncia final\")\n",
        "\n",
        "    print(\"\\nEste projeto demonstra:\")\n",
        "    print(\"â€¢ Uso de dataset de ALTA QUALIDADE com anotaÃ§Ãµes manuais precisas\")\n",
        "    print(\"â€¢ 903 anotaÃ§Ãµes de vagas em 30 imagens (30 vagas/imagem)\")\n",
        "    print(\"â€¢ Labels profissionais baseados em polÃ­gonos convertidos para YOLO\")\n",
        "    print(\"â€¢ Treinamento otimizado para dataset de qualidade superior\")\n",
        "    print(\"â€¢ DetecÃ§Ã£o precisa de vagas livres e ocupadas\")\n",
        "\n",
        "    print(\"\\nğŸ‰ SUCESSO TOTAL COM DATASET NOVO DE ALTA QUALIDADE! âœ“\")\n",
        "else:\n",
        "    print(\"Projeto executado com limitaÃ§Ãµes\")\n",
        "\n",
        "print(\"\\n--- Testes e InferÃªncia Final concluÃ­dos ---\")"
      ],
      "metadata": {
        "id": "GdbUfqiH_j09"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}