{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zcmFrwX1fpR",
        "outputId": "1fde755e-a2a9-43d4-f611-3b3c01bff985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Configurando ambiente Google Colab com GitHub ---\n",
            "Clonando repositório: https://github.com/kralluz/trabalho_inteligencia_artificial.git...\n",
            "Cloning into 'trabalho_inteligencia_artificial'...\n",
            "remote: Enumerating objects: 804, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 804 (delta 0), reused 1 (delta 0), pack-reused 801 (from 2)\u001b[K\n",
            "Receiving objects: 100% (804/804), 325.45 MiB | 28.99 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n",
            "Updating files: 100% (210/210), done.\n",
            "Diretório de trabalho atual: /content/trabalho_inteligencia_artificial\n",
            "\n",
            "Verificando conteúdo do diretório do projeto (primeiros 5 itens):\n",
            "- projeto_final_novo\n",
            "- .git\n",
            "- imagens_para_inferencia\n",
            "- yolov8n.pt\n",
            "- dataset_novo\n",
            "... e mais 5 itens.\n",
            "\n",
            "--- Configuração inicial e clone do GitHub concluídos ---\n"
          ]
        }
      ],
      "source": [
        "# Célula 1: Clonar o Repositório GitHub e Mudar para o Diretório do Projeto\n",
        "import os\n",
        "import shutil  # Operações de cópia e movimentação de arquivos\n",
        "import subprocess  # Execução de comandos externos\n",
        "import sys  # Acesso ao sistema e argumentos da linha de comando\n",
        "import time\n",
        "import traceback  # Exibição detalhada de erros e exceções\n",
        "\n",
        "import numpy as np  # Operações matemáticas e manipulação de arrays\n",
        "import torch  # Processamento e inferência com modelos PyTorch\n",
        "from PIL import Image  # Manipulação de imagens\n",
        "from ultralytics import YOLO  # Uso do modelo YOLO para detecção de objetos\n",
        "\n",
        "print(\"--- Configurando ambiente Google Colab com GitHub ---\")\n",
        "\n",
        "# --- PARÂMETROS DO SEU REPOSITÓRIO ---\n",
        "# URL do seu repositório GitHub\n",
        "GIT_REPO_URL = 'https://github.com/kralluz/trabalho_inteligencia_artificial.git'\n",
        "\n",
        "# Nome da pasta do repositório após o clone (geralmente o nome do repositório)\n",
        "REPO_NAME = 'trabalho_inteligencia_artificial'\n",
        "# -----------------------------------\n",
        "\n",
        "# Clonar o repositório\n",
        "print(f\"Clonando repositório: {GIT_REPO_URL}...\")\n",
        "if os.path.exists(REPO_NAME):\n",
        "    print(f\"Diretório '{REPO_NAME}' já existe. Removendo para clonar novamente...\")\n",
        "    !rm -rf {REPO_NAME}\n",
        "!git clone {GIT_REPO_URL}\n",
        "\n",
        "# Mudar o diretório de trabalho para a raiz do repositório clonado\n",
        "# Isso é crucial para que os caminhos relativos no seu script funcionem\n",
        "os.chdir(REPO_NAME)\n",
        "print(f\"Diretório de trabalho atual: {os.getcwd()}\")\n",
        "\n",
        "print(\"\\nVerificando conteúdo do diretório do projeto (primeiros 5 itens):\")\n",
        "try:\n",
        "    listed_items = os.listdir('.')\n",
        "    for i, item in enumerate(listed_items[:5]):\n",
        "        print(f\"- {item}\")\n",
        "    if len(listed_items) > 5:\n",
        "        print(f\"... e mais {len(listed_items) - 5} itens.\")\n",
        "    elif not listed_items:\n",
        "        print(\"O diretório do projeto parece estar vazio após o clone.\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao listar o diretório: {e}\")\n",
        "\n",
        "print(\"\\n--- Configuração inicial e clone do GitHub concluídos ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 2: Instalação de Dependências\n",
        "print(\"--- [1/6] Instalando dependências... ---\")\n",
        "\n",
        "deps = [\n",
        "    \"pip install ultralytics==8.3.153 --quiet\",\n",
        "    \"pip install Pillow numpy matplotlib --quiet\"\n",
        "]\n",
        "\n",
        "for dep in deps:\n",
        "    try:\n",
        "        print(f\"Executando: {dep}\")\n",
        "        # Usamos '!' para executar comandos de shell diretamente no Colab\n",
        "        !{dep}\n",
        "        print(f\"✓ {dep.split()[2]} instalado/verificado.\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Erro ao instalar {dep.split()[2]}: {e}\")\n",
        "        print(f\"~ {dep.split()[2]} (pode já estar instalado ou houve outro problema).\")\n",
        "\n",
        "print(\"\\n--- Instalação de dependências concluída ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLEHpFBE13Y6",
        "outputId": "f264e09a-efc1-4fac-8012-7864497012de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- [1/6] Instalando dependências... ---\n",
            "Executando: pip install ultralytics==8.3.153 --quiet\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✓ ultralytics==8.3.153 instalado/verificado.\n",
            "Executando: pip install Pillow numpy matplotlib --quiet\n",
            "✓ Pillow instalado/verificado.\n",
            "\n",
            "--- Instalação de dependências concluída ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 3: Definição da Função 'configurar_dataset_novo()'\n",
        "\n",
        "print(\"--- Definindo a função 'configurar_dataset_novo()' ---\")\n",
        "\n",
        "def configurar_dataset_novo():\n",
        "    \"\"\"Configura o dataset YOLO novo (convertido com alta qualidade)\"\"\"\n",
        "    print(\"🚗 Configurando dataset YOLO novo (alta qualidade)...\")\n",
        "\n",
        "    base_path = os.getcwd()\n",
        "    dataset_path = os.path.join(base_path, \"dataset_yolo_novo\")\n",
        "    yaml_path = os.path.join(dataset_path, \"data.yaml\")\n",
        "\n",
        "    # Verificar se o dataset existe\n",
        "    if not os.path.exists(dataset_path):\n",
        "        print(\"❌ Dataset YOLO novo não encontrado!\")\n",
        "        print(\"💡 Certifique-se de que 'dataset_yolo_novo' está na raiz do seu repositório GitHub.\")\n",
        "        return None\n",
        "\n",
        "    if not os.path.exists(yaml_path):\n",
        "        print(\"❌ Arquivo data.yaml não encontrado!\")\n",
        "        print(f\"💡 Certifique-se de que '{yaml_path}' existe no seu repositório GitHub.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"✅ Dataset YOLO novo configurado: {dataset_path}\")\n",
        "    print(f\"📄 Usando configuração: {yaml_path}\")\n",
        "\n",
        "    # Verificar estrutura do dataset\n",
        "    total_annotations = 0\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        img_dir = os.path.join(dataset_path, split, 'images')\n",
        "        lbl_dir = os.path.join(dataset_path, split, 'labels')\n",
        "\n",
        "        if os.path.exists(img_dir) and os.path.exists(lbl_dir):\n",
        "            img_count = len([f for f in os.listdir(img_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "            lbl_count = len([f for f in os.listdir(lbl_dir) if f.lower().endswith('.txt')])\n",
        "\n",
        "            # Contar anotações\n",
        "            for lbl_file in os.listdir(lbl_dir):\n",
        "                if lbl_file.lower().endswith('.txt'):\n",
        "                    lbl_path = os.path.join(lbl_dir, lbl_file)\n",
        "                    with open(lbl_path, 'r') as f:\n",
        "                        total_annotations += len(f.readlines())\n",
        "\n",
        "            print(f\"  📂 {split}: {img_count} imagens, {lbl_count} labels\")\n",
        "        else:\n",
        "            print(f\"  ⚠️ {split}: diretório '{split}' não encontrado ou incompleto em {dataset_path}\")\n",
        "\n",
        "    print(f\"📊 Total de anotações: {total_annotations}\")\n",
        "    return yaml_path\n",
        "\n",
        "print(\"\\n--- Função 'configurar_dataset_novo()' definida ---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhQujC-i16h7",
        "outputId": "fb1a6aa7-a1dd-4f0e-9e7f-14cb8ee0fb1b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Definindo a função 'configurar_dataset_novo()' ---\n",
            "\n",
            "--- Função 'configurar_dataset_novo()' definida ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 4: Início da Função 'main()' - Importações e Configuração do Dataset\n",
        "\n",
        "# Bloco de inicialização da função main()\n",
        "print(\"=\" * 70)\n",
        "print(\"TRABALHO FINAL - INTELIGENCIA ARTIFICIAL\")\n",
        "print(\"Detecção de Vagas de Estacionamento com YOLO\")\n",
        "print(\"VERSÃO FINAL - DATASET NOVO DE ALTA QUALIDADE\")\n",
        "print(\"903 anotações precisas em 30 imagens\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "start_time = time.time() # Inicia a contagem de tempo\n",
        "\n",
        "print(\"\\n[2/6] Importando bibliotecas...\")\n",
        "try:\n",
        "    # As importações já estão no topo da célula\n",
        "    print(\"✓ Todas as bibliotecas importadas\")\n",
        "except ImportError as e:\n",
        "    print(f\"✗ Erro de importação: {e}\")\n",
        "    # sys.exit(1) # Pode adicionar um sys.exit(1) para parar a execução em caso de erro fatal\n",
        "\n",
        "print(\"\\n[3/6] Configurando dataset YOLO novo (alta qualidade)...\")\n",
        "try:\n",
        "    # Chama a função definida na Célula 3\n",
        "    yaml_path = configurar_dataset_novo()\n",
        "    if yaml_path:\n",
        "        print(\"✅ Dataset YOLO novo configurado com sucesso\")\n",
        "    else:\n",
        "        print(\"❌ Erro ao configurar dataset YOLO novo\")\n",
        "        # sys.exit(1) # Pode adicionar um sys.exit(1) para parar a execução em caso de erro fatal\n",
        "except Exception as e:\n",
        "    print(f\"✗ Erro ao configurar dataset: {e}\")\n",
        "    # sys.exit(1) # Pode adicionar um sys.exit(1) para parar a execução em caso de erro fatal\n",
        "\n",
        "print(\"\\n[4/6] Carregando modelo YOLO...\")\n",
        "try:\n",
        "    # Tentar carregar modelo pré-treinado\n",
        "    try:\n",
        "        model = YOLO('yolov8n.pt')\n",
        "        print(\"✓ Modelo pré-treinado yolov8n.pt carregado\")\n",
        "    except Exception as e1:\n",
        "        print(f\"~ Não foi possível carregar yolov8n.pt ({e1}), tentando yolov8n.yaml...\")\n",
        "        try:\n",
        "            model = YOLO('yolov8n.yaml')\n",
        "            print(\"✓ Modelo criado do zero a partir de yolov8n.yaml\")\n",
        "        except Exception as e2:\n",
        "            print(f\"✗ Erro ao criar modelo com yolov8n.yaml: {e2}\")\n",
        "            # sys.exit(1) # Pode adicionar um sys.exit(1)\n",
        "except Exception as e:\n",
        "    print(f\"✗ Erro fatal ao carregar/criar modelo: {e}\")\n",
        "    # sys.exit(1) # Pode adicionar um sys.exit(1)\n",
        "\n",
        "# As variáveis 'model' e 'yaml_path' precisam ser acessíveis nas próximas células.\n",
        "# Em notebooks, variáveis definidas em uma célula são acessíveis nas seguintes.\n",
        "print(\"\\n--- Importações e Configuração do Dataset concluídas ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMUEPUlg2Wi9",
        "outputId": "c0b1410e-0986-45c3-9908-7b884d81039a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "TRABALHO FINAL - INTELIGENCIA ARTIFICIAL\n",
            "Detecção de Vagas de Estacionamento com YOLO\n",
            "VERSÃO FINAL - DATASET NOVO DE ALTA QUALIDADE\n",
            "903 anotações precisas em 30 imagens\n",
            "======================================================================\n",
            "\n",
            "[2/6] Importando bibliotecas...\n",
            "✓ Todas as bibliotecas importadas\n",
            "\n",
            "[3/6] Configurando dataset YOLO novo (alta qualidade)...\n",
            "🚗 Configurando dataset YOLO novo (alta qualidade)...\n",
            "✅ Dataset YOLO novo configurado: /content/trabalho_inteligencia_artificial/dataset_yolo_novo\n",
            "📄 Usando configuração: /content/trabalho_inteligencia_artificial/dataset_yolo_novo/data.yaml\n",
            "  📂 train: 21 imagens, 21 labels\n",
            "  📂 val: 4 imagens, 4 labels\n",
            "  📂 test: 5 imagens, 5 labels\n",
            "📊 Total de anotações: 903\n",
            "✅ Dataset YOLO novo configurado com sucesso\n",
            "\n",
            "[4/6] Carregando modelo YOLO...\n",
            "✓ Modelo pré-treinado yolov8n.pt carregado\n",
            "\n",
            "--- Importações e Configuração do Dataset concluídas ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 5: Treinamento do Modelo\n",
        "print(\"--- [5/6] Treinando modelo com dataset de alta qualidade... ---\")\n",
        "\n",
        "try:\n",
        "    print(\"Iniciando treinamento (pode demorar alguns minutos)...\")\n",
        "    print(\"📊 Dataset: 903 anotações precisas de vagas!\")\n",
        "\n",
        "    # Limpar projetos anteriores\n",
        "    if os.path.exists('projeto_final_novo'):\n",
        "        print(\"Removendo treinamento anterior...\")\n",
        "        shutil.rmtree('projeto_final_novo')\n",
        "\n",
        "    # Configurações de treinamento otimizadas para o novo dataset\n",
        "    results = model.train( # 'model' e 'yaml_path' são acessíveis da Célula 4\n",
        "        data=yaml_path,\n",
        "        epochs=150,           # Menos épocas pois o dataset é de alta qualidade\n",
        "        batch=8,              # Batch maior pois temos menos imagens mas mais anotações\n",
        "        imgsz=640,            # Resolução maior para melhor precisão\n",
        "        device='cpu',         # Mantenha 'cpu' ou mude para '0'/'cuda' se for usar GPU\n",
        "        project='projeto_final_novo',\n",
        "        name='yolo_vagas_novo',\n",
        "        exist_ok=True,\n",
        "        pretrained=True,\n",
        "        optimizer='AdamW',    # Otimizador mais moderno\n",
        "        verbose=True,\n",
        "        seed=42,\n",
        "        deterministic=True,\n",
        "        patience=10,          # Early stopping mais agressivo\n",
        "        save_period=5,        # Salvar checkpoints a cada 5 épocas\n",
        "        val=True,\n",
        "        cache=False,\n",
        "        lr0=0.01,             # Learning rate inicial\n",
        "        warmup_epochs=3       # Warmup epochs\n",
        "    )\n",
        "    print(f\"✓ Treinamento concluído! Resultados salvos em: {results.save_dir}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"✗ Erro no treinamento: {e}\")\n",
        "    print(\"Detalhes do erro:\")\n",
        "    traceback.print_exc()\n",
        "    print(\"Continuando com validação...\")\n",
        "\n",
        "print(\"\\n--- Treinamento do modelo concluído ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXgbmIOx_he_",
        "outputId": "968964b9-c1af-4877-ec37-395695e531d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- [5/6] Treinando modelo com dataset de alta qualidade... ---\n",
            "Iniciando treinamento (pode demorar alguns minutos)...\n",
            "📊 Dataset: 903 anotações precisas de vagas!\n",
            "Removendo treinamento anterior...\n",
            "New https://pypi.org/project/ultralytics/8.3.154 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.153 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/trabalho_inteligencia_artificial/dataset_yolo_novo/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=150, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_vagas_novo, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=projeto_final_novo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=projeto_final_novo/yolo_vagas_novo, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1579.9±946.0 MB/s, size: 282.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/trabalho_inteligencia_artificial/dataset_yolo_novo/train/labels.cache... 21 images, 0 backgrounds, 0 corrupt: 100%|██████████| 21/21 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1619.9±676.1 MB/s, size: 389.1 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/trabalho_inteligencia_artificial/dataset_yolo_novo/val/labels.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to projeto_final_novo/yolo_vagas_novo/labels.jpg... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mprojeto_final_novo/yolo_vagas_novo\u001b[0m\n",
            "Starting training for 150 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/150         0G      1.462      3.404      1.348        333        640:  33%|███▎      | 1/3 [00:08<00:17,  8.87s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 6: Testes e Inferência Final\n",
        "print(\"--- [6/6] Testando modelo e realizando inferência final... ---\")\n",
        "\n",
        "model_path_best = os.path.join('projeto_final_novo', 'yolo_vagas_novo', 'weights', 'best.pt')\n",
        "model_path_last = os.path.join('projeto_final_novo', 'yolo_vagas_novo', 'weights', 'last.pt')\n",
        "\n",
        "loaded_model = None\n",
        "if os.path.exists(model_path_best):\n",
        "    try:\n",
        "        loaded_model = YOLO(model_path_best)\n",
        "        print(f\"✓ Modelo treinado carregado: {model_path_best}\")\n",
        "    except Exception as e_best:\n",
        "        print(f\"~ Problema ao carregar best.pt ({e_best}), tentando last.pt...\")\n",
        "        if os.path.exists(model_path_last):\n",
        "            try:\n",
        "                loaded_model = YOLO(model_path_last)\n",
        "                print(f\"✓ Modelo treinado carregado: {model_path_last}\")\n",
        "            except Exception as e_last:\n",
        "                print(f\"~ Erro ao carregar last.pt ({e_last}). Teste abortado.\")\n",
        "elif os.path.exists(model_path_last):\n",
        "    try:\n",
        "        loaded_model = YOLO(model_path_last)\n",
        "        print(f\"✓ Modelo treinado carregado: {model_path_last}\")\n",
        "    except Exception as e_last:\n",
        "        print(f\"~ Erro ao carregar last.pt ({e_last}). Teste abortado.\")\n",
        "else:\n",
        "    print(\"~ Nenhum modelo treinado encontrado. Teste abortado.\")\n",
        "\n",
        "if loaded_model:\n",
        "    try:\n",
        "        # Diretório de teste\n",
        "        test_images_dir = os.path.join(os.path.dirname(yaml_path), 'test', 'images')\n",
        "\n",
        "        # Criar diretório para resultados da inferência\n",
        "        results_dir = \"resultados_novo/predicoes_finais\"\n",
        "        os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"Realizando inferência nas imagens de teste em: {test_images_dir}\")\n",
        "        print(f\"Resultados serão salvos em: {results_dir}\")\n",
        "\n",
        "        results_pred = loaded_model.predict(\n",
        "            source=test_images_dir,\n",
        "            save=True,\n",
        "            project=\"resultados_novo\",\n",
        "            name=\"predicoes_finais\",\n",
        "            exist_ok=True,\n",
        "            conf=0.1,   # Confiança mais baixa para capturar mais detecções\n",
        "            iou=0.5,    # IoU para NMS\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        # Analisar resultados detalhadamente\n",
        "        total_detections = 0\n",
        "        for i, result in enumerate(results_pred):\n",
        "            if result.boxes is not None and len(result.boxes) > 0:\n",
        "                detections = len(result.boxes)\n",
        "                total_detections += detections\n",
        "                print(f\"  📸 Imagem {i+1}: {detections} vagas detectadas\")\n",
        "\n",
        "                if i < 3:  # Mostrar detalhes das 3 primeiras imagens\n",
        "                    for j, box in enumerate(result.boxes[:5]):  # Max 5 detecções por imagem\n",
        "                        cls = int(box.cls[0])\n",
        "                        conf = float(box.conf[0])\n",
        "                        class_name = loaded_model.names[cls]\n",
        "                        print(f\"    - Vaga {j+1}: {class_name} (confiança: {conf:.2f})\")\n",
        "            else:\n",
        "                print(f\"  📸 Imagem {i+1}: 0 vagas detectadas\")\n",
        "\n",
        "        print(f\"✓ Teste concluído! {len(results_pred)} imagens processadas.\")\n",
        "        print(f\"📊 Total de detecções: {total_detections}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"~ Erro no teste: {e}\")\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"~ Modelo não carregado, pulando etapa de teste.\")\n",
        "\n",
        "# Teste final com imagens para inferência\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"🚗 TESTE FINAL COM IMAGENS DE INFERÊNCIA\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "inference_images_path = os.path.join(os.getcwd(), 'imagens_para_inferencia')\n",
        "\n",
        "if loaded_model and os.path.exists(inference_images_path):\n",
        "    try:\n",
        "        print(f\"Realizando inferência final com dataset de alta qualidade em: {inference_images_path}\")\n",
        "\n",
        "        inference_results = loaded_model.predict(\n",
        "            source=inference_images_path,\n",
        "            save=True,\n",
        "            project='teste_final_novo',\n",
        "            name='inferencia_final',\n",
        "            exist_ok=True,\n",
        "            conf=0.1,   # Confiança baixa para capturar mais detecções\n",
        "            iou=0.5,\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        # Analisar resultados da inferência final\n",
        "        total_detections = 0\n",
        "        for result in inference_results:\n",
        "            if result.boxes is not None:\n",
        "                detections = len(result.boxes)\n",
        "                total_detections += detections\n",
        "\n",
        "                # Analisar por classe\n",
        "                free_count = 0\n",
        "                occupied_count = 0\n",
        "\n",
        "                for box in result.boxes:\n",
        "                    cls = int(box.cls[0])\n",
        "                    conf = float(box.conf[0])\n",
        "\n",
        "                    if loaded_model.names[cls] == 'free_parking_space':\n",
        "                        free_count += 1\n",
        "                    elif loaded_model.names[cls] == 'not_free_parking_space':\n",
        "                        occupied_count += 1\n",
        "\n",
        "                print(f\"  📸 {os.path.basename(result.path)}: {detections} vagas\")\n",
        "                print(f\"    🟢 Livres: {free_count} | 🔴 Ocupadas: {occupied_count}\")\n",
        "            else:\n",
        "                print(f\"  📸 {os.path.basename(result.path)}: 0 vagas detectadas\")\n",
        "\n",
        "        print(f\"\\n✓ Inferência final concluída! {len(inference_results)} imagens processadas.\")\n",
        "        print(f\"📁 Resultados salvos em: teste_final_novo/inferencia_final/\")\n",
        "        print(f\"📊 Total de detecções: {total_detections}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Erro na inferência final: {e}\")\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"~ Diretório 'imagens_para_inferencia' não encontrado ou modelo não carregado. Pulando inferência final.\")\n",
        "\n",
        "# Resumo final\n",
        "end_time = time.time() # A variável start_time é do início da Célula 4\n",
        "duration = (end_time - start_time) / 60\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PROJETO CONCLUÍDO COM DATASET DE ALTA QUALIDADE!\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Tempo total: {duration:.1f} minutos\")\n",
        "\n",
        "if os.path.exists('projeto_final_novo'):\n",
        "    print(\"\\nArquivos criados:\")\n",
        "    print(\"✓ dataset_yolo_novo/ - Dataset de alta qualidade (903 anotações)\")\n",
        "    print(\"✓ projeto_final_novo/ - Modelo treinado\")\n",
        "    if os.path.exists('resultados_novo'):\n",
        "        print(\"✓ resultados_novo/ - Predições do teste\")\n",
        "    if os.path.exists('teste_final_novo'):\n",
        "        print(\"✓ teste_final_novo/ - Inferência final\")\n",
        "\n",
        "    print(\"\\nEste projeto demonstra:\")\n",
        "    print(\"• Uso de dataset de ALTA QUALIDADE com anotações manuais precisas\")\n",
        "    print(\"• 903 anotações de vagas em 30 imagens (30 vagas/imagem)\")\n",
        "    print(\"• Labels profissionais baseados em polígonos convertidos para YOLO\")\n",
        "    print(\"• Treinamento otimizado para dataset de qualidade superior\")\n",
        "    print(\"• Detecção precisa de vagas livres e ocupadas\")\n",
        "\n",
        "    print(\"\\n🎉 SUCESSO TOTAL COM DATASET NOVO DE ALTA QUALIDADE! ✓\")\n",
        "else:\n",
        "    print(\"Projeto executado com limitações\")\n",
        "\n",
        "print(\"\\n--- Testes e Inferência Final concluídos ---\")"
      ],
      "metadata": {
        "id": "GdbUfqiH_j09"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}